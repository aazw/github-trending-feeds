name: scrape_weekly_trending
on:
  # Cron job
  schedule:
    # every Monday
    # - cron: '0 11 * * 1' # UTC 11:00 = JST 20:00
    # - cron: '0 12 * * 1' # UTC 12:00 = JST 21:00
    # - cron: '0 13 * * 1' # UTC 13:00 = JST 22:00
    # - cron: '0 14 * * 1' # UTC 14:00 = JST 23:00
    # - cron: '0 15 * * 1' # UTC 15:00 = JST 24:00 (00:00)
    - cron: '0 16 * * 1' # UTC 16:00 = JST 25:00 (01:00)
    # - cron: '0 17 * * 1' # UTC 17:00 = JST 26:00 (02:00)
    # - cron: '0 18 * * 1' # UTC 18:00 = JST 27:00 (03:00)
    # - cron: '0 19 * * 1' # UTC 19:00 = JST 28:00 (04:00)
    # - cron: '0 20 * * 1' # UTC 20:00 = JST 29:00 (05:00)
    # - cron: '0 21 * * 1' # UTC 21:00 = JST 30:00 (06:00)
    # - cron: '0 22 * * 1' # UTC 22:00 = JST 31:00 (07:00)
    # - cron: '0 23 * * 1' # UTC 23:00 = JST 32:00 (08:00)

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

jobs:
  scrape_github_trending:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: pip install 
        run: pip install -r ./requirements.txt

      - name: scraping trending
        run: ./scripts/scrape_weekly_trending.sh

      - name: copy atoms
        run: |
          d=$(date -I)

          for atom in $(ls ./docs/feeds/*/weekly.atom); do
            mkdir -p "$(dirname $atom)/weekly"
            cp "${atom}" "$(dirname $atom)/weekly/weekly-${d}.atom"
          done
          
      - name: Create new commit
        run: |
          git config user.name  github-actions
          git config user.email github-actions@github.com
          git pull
          git add ./docs/feeds/
          git commit -m "add/update the file about weekly trending of github at $(date '+%Y-%m-%dT%H:%M:%S%z')" 
          git push
  